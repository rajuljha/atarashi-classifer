{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "788c2cdb-f2f8-47b9-9de3-b149f1d3c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import hashlib\n",
    "from typing import List, Set\n",
    "\n",
    "class MinHash:\n",
    "    def __init__(self, num_hashes: int = 100):\n",
    "        self.num_hashes = num_hashes\n",
    "        self.max_hash = (1 << 32) - 1\n",
    "        self.hash_funcs = self._generate_hash_functions()\n",
    "\n",
    "    def _generate_hash_functions(self):\n",
    "        random.seed(42)\n",
    "        return [\n",
    "            (random.randint(1, self.max_hash), random.randint(0, self.max_hash))\n",
    "            for _ in range(self.num_hashes)\n",
    "        ]\n",
    "\n",
    "    def _hash(self, x: str, a: int, b: int) -> int:\n",
    "        return (a * hash(x) + b) % self.max_hash\n",
    "\n",
    "    def compute_signature(self, tokens: Set[str]) -> List[int]:\n",
    "        signature = []\n",
    "        for a, b in self.hash_funcs:\n",
    "            min_hash = min(self._hash(token, a, b) for token in tokens)\n",
    "            signature.append(min_hash)\n",
    "        return signature\n",
    "\n",
    "class LSHIndex:\n",
    "    def __init__(self, num_bands: int = 20):\n",
    "        self.num_bands = num_bands\n",
    "        self.buckets = [{} for _ in range(num_bands)]\n",
    "        self.documents = {}\n",
    "\n",
    "    def _band_hash(self, band: List[int]) -> str:\n",
    "        return hashlib.sha1(str(band).encode()).hexdigest()\n",
    "\n",
    "    def add(self, doc_id: str, signature: List[int]):\n",
    "        self.documents[doc_id] = signature\n",
    "        rows_per_band = len(signature) // self.num_bands\n",
    "        for i in range(self.num_bands):\n",
    "            band = signature[i * rows_per_band: (i + 1) * rows_per_band]\n",
    "            band_hash = self._band_hash(band)\n",
    "            if band_hash not in self.buckets[i]:\n",
    "                self.buckets[i][band_hash] = set()\n",
    "            self.buckets[i][band_hash].add(doc_id)\n",
    "\n",
    "    def query(self, signature: List[int]) -> Set[str]:\n",
    "        candidates = set()\n",
    "        rows_per_band = len(signature) // self.num_bands\n",
    "        for i in range(self.num_bands):\n",
    "            band = signature[i * rows_per_band: (i + 1) * rows_per_band]\n",
    "            band_hash = self._band_hash(band)\n",
    "            if band_hash in self.buckets[i]:\n",
    "                candidates.update(self.buckets[i][band_hash])\n",
    "        return candidates\n",
    "\n",
    "    def save(self, path: str):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump((self.buckets, self.documents), f)\n",
    "\n",
    "    def load(self, path: str):\n",
    "        with open(path, 'rb') as f:\n",
    "            self.buckets, self.documents = pickle.load(f)\n",
    "\n",
    "class LicenseClassifier:\n",
    "    def __init__(self, num_hashes: int = 100, num_bands: int = 20):\n",
    "        self.minhash = MinHash(num_hashes)\n",
    "        self.index = LSHIndex(num_bands)\n",
    "\n",
    "    def _tokenize(self, text: str) -> Set[str]:\n",
    "        return set(text.lower().split())\n",
    "\n",
    "    def index_from_folders(self, folder_paths: List[str], n_samples: int = 2):\n",
    "        for folder in folder_paths:\n",
    "            all_files = [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "            selected = random.sample(all_files, min(n_samples, len(all_files)))\n",
    "            for file_path in selected:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    tokens = self._tokenize(f.read())\n",
    "                    signature = self.minhash.compute_signature(tokens)\n",
    "                    self.index.add(file_path, signature)\n",
    "\n",
    "    def classify(self, text: str, threshold: float = 0.8) -> bool:\n",
    "        tokens = self._tokenize(text)\n",
    "        signature = self.minhash.compute_signature(tokens)\n",
    "        candidates = self.index.query(signature)\n",
    "        for candidate in candidates:\n",
    "            candidate_sig = self.index.documents[candidate]\n",
    "            similarity = self._jaccard_similarity(signature, candidate_sig)\n",
    "            if similarity >= threshold:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _jaccard_similarity(self, sig1: List[int], sig2: List[int]) -> float:\n",
    "        matches = sum(1 for i, j in zip(sig1, sig2) if i == j)\n",
    "        return matches / len(sig1)\n",
    "\n",
    "    def save_index(self, path: str):\n",
    "        self.index.save(path)\n",
    "\n",
    "    def load_index(self, path: str):\n",
    "        self.index.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0b47564-e9a2-40ea-b25f-0324f306bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier\n",
    "classifier = LicenseClassifier(num_hashes=100, num_bands=20)\n",
    "\n",
    "# Index 2 files randomly from each license folder\n",
    "license_folders = [\"Split-DB-Foss-Licenses\", \"Split-SPDX-licenses\"]\n",
    "classifier.index_from_folders(license_folders, n_samples=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b739280-8c3d-4c2d-b412-126fbee2ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index to disk\n",
    "classifier.save_index(\"license_index.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f221c19-26ef-4c03-a04a-ac6d8b4a1f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: ❌ | Expected: True | Predicted: False\n",
      "Query 2: ❌ | Expected: True | Predicted: False\n",
      "Query 3: ✅ | Expected: False | Predicted: False\n",
      "Query 4: ✅ | Expected: False | Predicted: False\n",
      "Query 5: ❌ | Expected: True | Predicted: False\n",
      "Query 6: ✅ | Expected: False | Predicted: False\n",
      "\n",
      "Accuracy: 3/6 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "classifier = LicenseClassifier()\n",
    "classifier.load_index(\"license_index.pkl\")\n",
    "\n",
    "# Step 2: Define test queries and their expected labels\n",
    "# True = license, False = non-license\n",
    "test_cases = [\n",
    "    (\"Permission is hereby granted, free of charge, to any person obtaining a copy...\", True),\n",
    "    (\"This software is licensed under the MIT License.\", True),\n",
    "    (\"Welcome to our website. We use cookies for analytics.\", False),\n",
    "    (\"Please enter your name and email address below.\", False),\n",
    "    (\"Redistribution and use in source and binary forms, with or without modification...\", True),\n",
    "    (\"To continue, please update your payment method.\", False)\n",
    "]\n",
    "\n",
    "# Step 3: Classify and evaluate\n",
    "correct = 0\n",
    "for idx, (text, expected) in enumerate(test_cases):\n",
    "    predicted = classifier.classify(text, threshold=0.5)\n",
    "    result = \"✅\" if predicted == expected else \"❌\"\n",
    "    print(f\"Query {idx+1}: {result} | Expected: {expected} | Predicted: {predicted}\")\n",
    "\n",
    "    if predicted == expected:\n",
    "        correct += 1\n",
    "\n",
    "# Step 4: Print summary\n",
    "total = len(test_cases)\n",
    "print(f\"\\nAccuracy: {correct}/{total} ({(correct/total)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b821c10-6c90-4362-835d-1a96eafdab0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a2102-b991-409f-832a-3867e17de1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
